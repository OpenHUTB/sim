%!TEX root = ../../csuthesis_main.tex

\chapter{总结与展望}

\section{工作总结}
随着自动驾驶技术逐步迈向实际应用，复杂动态场景下的环境感知与行为预测能力成为制约系统安全性与智能水平的关键瓶颈。本文聚焦于自动驾驶视觉感知中的目标跟踪与意图分析问题，以提升感知系统的前瞻性决策支持能力为核心目标，通过理论分析、算法改进与系统集成三个层面的协同研究，构建了一套基于Carla仿真平台的改进目标跟踪与意图分析算法，为自动驾驶感知层提供了从动态目标检测到行为预测的完整解决方案。

在理论研究层面，本文系统梳理了目标检测、多目标跟踪及意图识别领域的国内外研究现状，剖析了传统算法在复杂交通场景下的局限性。针对DeepSORT算法在目标遮挡与运动模糊场景下的特征敏感性不足问题，创新性地引入SIFT特征提取机制，通过融合尺度不变特征与运动轨迹预测，有效提升了目标身份关联的鲁棒性。同时，基于相对运动学原理构建轻量化意图识别模型，通过速度-距离联合判据实现了对目标行为趋向的实时分级预警，突破了传统跟踪算法仅关注空间位置的局限性。

在技术实现层面，本研究依托Carla仿真平台构建了高真实度的动态交通场景，设计了包含图像采集、标注存储、同步控制等功能的数据处理流程，为算法验证提供了可靠的多模态数据集。通过改进的DeepSORT算法与意图分析模块的深度耦合，实现了跟踪-识别-反馈的闭环处理架构。实验结果表明，改进后的跟踪算法在Town10密集场景下的IDF1指标提升至86.5\%，身份切换次数降为零，同时系统整体处理帧率稳定在9.09 FPS，验证了算法改进的有效性与工程可行性。

在集成验证层面，基于模块化设计理念构建了具备人机交互功能的可视化场景，通过PyGame实时渲染模块实现了跟踪框、速度信息与意图提示的多层次信息叠加。该实验不仅验证了理论模型的实用性，更通过键盘操控、数据记录与性能分析功能的集成，为后续算法优化与应用拓展提供了可扩展的技术框架。

本研究从自动驾驶实际需求出发，通过算法改进与实验验证，实现了视觉感知从“目标定位”到“行为预判”的功能跨越。研究成果不仅为复杂场景下的目标跟踪提供了新的技术路径，其轻量化的意图识别架构更为车载嵌入式系统的实时行为预测提供了有价值的参考范式。

\section{研究不足}

尽管本研究于自动驾驶视觉感知领域收获了阶段性成果，然而因研究条件以及技术路径的限制，仍存在如下需要完善之处：

其一，场景泛化能力需要强化。实验验证主要是基于Carla平台的静态光照以及理想天气场景展开，并未充分模拟出雨雪、雾霾、夜间等复杂环境下的感知挑战，实际道路中由逆光、水面积反射等引发的图像噪声问题未被纳入测试范畴，这有可能致使算法在极端条件下的鲁棒性评估出现偏差。并且当前意图识别模型未考虑非结构化道路中目标行为的特殊性，限制了模型的场景适应性。

其二，多目标交互建模深度不足。 现有系统采用单目标跟踪与独立意图判别策略，并未构建目标间的协同运动关系模型，在交叉路口超车、车队跟驰等强交互场景中，单个目标的运动趋势往往会受到周边车辆行为的制约，而当前基于欧氏距离的简化判据很难刻画此类复杂动力学特征，这可能会导致意图误判率上升。比如前方车辆因避让行人而产生的减速行为，有可能被误识别为“危险靠近”状态。

其三，长期行为预测机制缺失。 研究采用的阈值化意图判别模型仅可捕捉目标的瞬时运动趋势，缺乏对连续行为链的时序建模能力，实验说明，当目标车辆执行连续变道或者渐进式加速时，系统容易出现意图标签频繁跳变现象。另外未引入道路拓扑先验知识，致使行为预测与场景语义脱节，难以支撑高阶决策需求。

其四，尽管改进算法在GPU加速下达到了准实时性能，但是9.09 FPS的帧率仍旧与车载嵌入式系统的硬实时要求存在差距，特征提取模块的SIFT-GPU实现依赖特定硬件架构，在车规级芯片上的计算效率尚未得到验证。当前系统以前向单目相机作为感知输入，未融合激光雷达、毫米波雷达等多源异构数据，制约了目标状态估计的精度与可靠性。

上述局限性反映出理论研究与工程实践之间的衔接缺口，需要依靠跨学科方法融合与技术创新来实现突破，具体优化路径将在后续研究中完善。

\section{后续优化方向}

面向自动驾驶感知系统实际应用需求，本文研究成果的深化可从多模态感知融合、行为预测模型升级以及工程落地优化这三个维度展开系统性探索，在算法层面，要突破单目视觉感知局限，探寻激光雷达点云与视觉特征的跨模态对齐方法，借助构建时空同步的多源数据关联框架，实现目标三维运动矢量的精准估计。针对复杂交互场景，可引入图注意力网络来建立车辆间动态关系模型，利用社会力模型量化周边交通参与者行为影响权重，以此在交叉路口合流、紧急避障等场景中提高群体行为预测准确性，结合Transformer架构的时序建模优势，设计长短时记忆融合机制，把瞬时意图判别拓展为基于轨迹片段的行为模式识别，让系统可捕捉“加速 - 变道 - 减速”等连续性驾驶策略的演化规律。

在场景适应性方面，需构建覆盖极端天气、光照突变以及传感器故障的仿真测试体系，凭借物理引擎提高的图像退化模型生成对抗性训练样本，提升特征提取模块的环境鲁棒性，针对道路拓扑先验知识缺失问题，可集成高精度地图的车道级语义信息，建立意图识别与车道线曲率、交通信号状态的耦合分析模型，使行为预测结果符合实际交通规则的约束逻辑。另外探索轻量化模型部署方案，借助神经网络架构搜索技术压缩SIFT - GPU加速模块的计算负载，结合车规级芯片的量化加速能力，力争在Jetson AGX Orin等嵌入式平台上实现30 FPS的硬实时处理性能。

在从技术验证朝着产业落地转化进程里，有必要把多传感器时空标定方法给予完善，还要开发出针对实际车载系统的异构计算框架，借助构建开源工具链，可降低多目标跟踪以及意图识别模块的集成复杂程度，促使研究成果朝着ADAS量产项目快速进行移植，未来工作还可拓展到行人、非机动车等弱势交通参与者的意图建模方面，结合因果推理方法去破解人车交互当中的意图博弈难题，最终构建成覆盖全要素、全场景的自动驾驶认知决策体系。


\begin{tabular}{l l}
%  \verb|\songti| & {\songti 宋体} \\
%  \verb|\heiti| & {\heiti 黑体} \\
%   \verb|\kaiti| & {\kaiti 楷体}
\end{tabular}
