%!TEX root = ../csuthesis_main.tex
\keywordsen{Pedestrian navigation, Reinforcement learning, Virtual simulation, Carla platform, Path planning, Obstacle avoidance}
\begin{abstracten}

With the advancement of smart city infrastructure, pedestrian navigation systems face increasing challenges in handling complex and dynamic urban environments. Traditional rule-based planning approaches struggle to adapt to real-time variations in pedestrian behavior. This study proposes a pedestrian navigation and control system based on the Unreal Engine and Carla platform, integrating reinforcement learning to optimize path planning and obstacle avoidance. By simulating realistic traffic scenarios, the system provides a high-fidelity virtual environment for training and evaluating intelligent agents. Reinforcement learning algorithms such as DQN and PPO are applied to improve navigation decision-making, guided by a multi-dimensional reward function that balances goal achievement, safety, and path efficiency. Experiments conducted in various simulation scenarios demonstrate the system's effectiveness in enhancing navigation accuracy, obstacle avoidance success, and overall planning efficiency. The results validate the feasibility of combining virtual simulation with reinforcement learning, offering a scalable and cost-effective approach to intelligent pedestrian navigation, and laying the groundwork for future research in multi-agent collaboration and intelligent traffic systems.

\end{abstracten}
