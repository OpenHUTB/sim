\%!TEX root = ../../csuthesis\_main.tex

\chapter{技术实现}
\subsection{技术实现要素}
多传感器融合的环境感知系统
智能驾驶车辆通过融合多种传感器（如激光雷达、毫米波雷达、摄像头等）实现对周围环境的全面感知。​这种多传感器融合技术能够提供360度的视野，实时检测并跟踪周围的交通参与者和障碍物，为决策和规划模块提供准确的环境信息。 ​


高精度地图与定位技术
高精度地图结合实时定位技术（如RTK、IMU等）为智能驾驶车辆提供精确的位置信息和道路元素数据。​这种技术支持车辆在复杂道路环境中的精确导航和路径规划，确保行驶安全。 ​


多模态大模型AI安全员
引入多模态大模型作为AI安全员，可以实时处理来自摄像头的图像数据，识别车辆行驶过程中遇到的危险场景和异常情况。​这种AI安全员具备跨模态理解能力，能够应对传统算法难以覆盖的长尾场景，如不规则路面、临时施工区域等，提升系统的安全性和鲁棒性。 ​


虚拟现实技术的仿真系统
利用虚拟现实技术构建的仿真系统，可以模拟各种驾驶场景，包括电子设备故障、系统功能局限、人员误操作等安全威胁。​通过三维建模和实时渲染，提供逼真的虚拟驾驶环境，用于测试和优化智能驾驶系统的响应能力。 ​

异常处理与自适应错误修复机制
在智能驾驶过程中，系统可能会遇到各种异常情况，如传感器失效、算法参数设置不合理等。​为此，系统需要具备异常处理和自适应错误修复机制，能够识别错误状态并采取相应的调整策略，确保车辆继续安全运行。 

多传感器融合的环境感知系统
智能驾驶车辆通过融合多种传感器（如激光雷达、毫米波雷达、摄像头等）实现对周围环境的全面感知。​这种多传感器融合技术能够提供360度的视野，实时检测并跟踪周围的交通参与者和障碍物，为决策和规划模块提供准确的环境信息。 ​

高精度地图与定位技术
高精度地图结合实时定位技术（如RTK、IMU等）为智能驾驶车辆提供精确的位置信息和道路元素数据。​这种技术支持车辆在复杂道路环境中的精确导航和路径规划，确保行驶安全。 ​

多模态大模型AI安全员
引入多模态大模型作为AI安全员，可以实时处理来自摄像头的图像数据，识别车辆行驶过程中遇到的危险场景和异常情况。​这种AI安全员具备跨模态理解能力，能够应对传统算法难以覆盖的长尾场景，如不规则路面、临时施工区域等，提升系统的安全性和鲁棒性。 ​

虚拟现实技术的仿真系统
利用虚拟现实技术构建的仿真系统，可以模拟各种驾驶场景，包括电子设备故障、系统功能局限、人员误操作等安全威胁。​通过三维建模和实时渲染，提供逼真的虚拟驾驶环境，用于测试和优化智能驾驶系统的响应能力。 ​

异常处理与自适应错误修复机制
在智能驾驶过程中，系统可能会遇到各种异常情况，如传感器失效、算法参数设置不合理等。​为此，系统需要具备异常处理和自适应错误修复机制，能够识别错误状态并采取相应的调整策略，确保车辆继续安全运行。 

\section{详细操作}

三维环境中的感知-运动控制仍然是机器学习和机器人学的一个主要挑战。自动驾驶车辆的发展是这个问题长期研究的一个实例[22，26]。它最困难的形式是在人口稠密的城市环境中导航[21]。这种场景带来更多的挑战，是因为：交通交叉口处复杂的多智能体动态；需要跟踪和响应几十个甚至数百个其他参与者的运动；需要识别街道标志、路灯以及道路标线，并区分多种类型的其他车辆；罕见事件的长尾——道路施工、儿童冲上道路、前方发生事故、其他车辆误入错误车道；以及迅速协调冲突目标的必要性。例如，当一个心不在焉的行人误入前面的道路，而另一辆车正从后面快速驶来，如果刹车过猛，可能会追尾。

城市自动驾驶的研究受到基础设施成本和现实世界中训练和测试系统的后勤困难的阻碍。一辆自动驾驶汽车的检测和操作也需要大量的资金和人力。而且，单辆车远远不足以收集必要的数据，这些数据涵盖了为训练和验证而必须处理的大量corner case。对于classic modular pipeline来说是如此，对于需要大量数据的深度学习技术更是如此。在现实世界中对城市驾驶的自动驾驶模型的训练和验证是大多数研究小组无法实现的。

另一种方法是在仿真中训练和验证驾驶策略。在自动驾驶研究的早期，仿真就被用于训练驾驶模型[22]。最近，赛车模拟器被用做评估自动驾驶的新方法[28，3]。自定义的仿真模拟也被用于训练和bench mark视觉感知系统[2，9，10，11，20，25，27，29]。商业游戏已经被用于获取高质量的数据，用于训练和bench mark视觉感知系统[23，24]。

虽然仿真在自主驾驶研究中的应用非常广泛，但现有的仿真平台有限。开源的赛车模拟器，如TORCS[28]并没有表现出城市驾驶的复杂性：它们缺乏行人、交叉口、交通规则以及其他区分城市驾驶和赛车赛道的复杂因素。高保真度模拟城市环境的商业游戏，如《侠盗猎车手5》[23，24]，可自定义的部分很有限。

本文介绍了一种开源的城市驾驶模拟器CARLA（Car Learning to Act）。CARLA从一开始就是为了支持自动驾驶模型的训练、原型设计和验证，包括感知和控制。CARLA是一个开源的平台。独一无二的是，CARLA提供的城市环境内容也是免费的。它包括城市布局、多种车辆模型、建筑物、行人、路标等。该仿真平台支持传感器套件的灵活设置，并提供可用于训练驾驶策略的信号，例如GPS坐标、速度、加速度以及碰撞和其他违规行为的详细数据。CARLA可以定义广泛的环境条件，包括天气和时间。

CARLA是为了在渲染和物理模拟方面的灵活性和真实性而设计的。它相当于在Unreal Engine 4（UE4）[7]之上涉及了一个开源层，支持未来的扩展。该引擎提供最先进的渲染质量、逼真的物理效果、基本的NPC逻辑和可互操作插件的生态系统。针对非商业用途，该引擎是免费的。

环境。环境由静态对象（如建筑物、植被、交通标志和基础设施）以及动态对象（如车辆和行人）的三维模型组成。所有模型都经过精心设计，以平衡视觉质量和渲染速度：我们使用低重量的几何模型和纹理，但通过精心制作材质和使用可变细节级别来保持视觉真实感。所有的三维模型都有一个共同的比例，它们的大小反映了真实物体的大小。在撰写本文时，我们的资产库包括40个不同的建筑、16个动画车辆模型和50个动画行人模型。

开发CARLA的一个挑战是非玩家角色的配置（这对仿真的保真度而言非常重要）。我们基于标准的UE4车型（PhysXVehicles）来设计非玩家车辆，其运动学参数调整为现实模式。我们还实现了一个控制非玩家车辆行为的基本控制器：车道跟随、遵守红绿灯、速度限制和交叉路口决策。车辆和行人可以相互察觉和避开。更先进的非玩家车辆控制器将被集成到未来的版本中[1]。

行人根据特定城镇的导航地图在镇上游荡，相互避开，尽量避开车辆。如果汽车与行人相撞，行人将从仿真世界中删除，并在短暂的时间间隔后在不同的位置生成新的行人。

为了增加视觉多样性，我们在将非玩家角色添加到仿真中时对其外观进行随机化。每个行人都穿着从预先指定的衣柜中随机抽取的一套衣服，并可选择配备以下一种或多种物品：智能手机、购物袋、吉他盒、手提箱、雨伞等。每辆车都是根据特定车型的一组材料随机喷漆的。

我们还实现了各种大气条件和照明条件。它们在太阳的位置和颜色、天空漫射的强度和颜色以及环境遮挡、大气雾、云量和降水量等方面存在差异。目前，CARLA支持两种照明条件（正午和日落）以及9种天气条件（不同的云量、降水量和街道上是否有水坑）。这将实现总共18种照明天气组合（为了简洁起见，我们将其称为天气。）

传感器。CARLA允许灵活配置传感器套件。在撰写本文时，传感器仅限于RGB摄像头和提供地面真实深度和语义分割的传感器。如图2所示。摄像头的数量及其类型和位置可由用户指定。摄像头参数包括三维位置、相对于汽车坐标系的三维方向、视野和景深。我们的语义分割伪传感器提供了12个语义类：道路、车道标线、交通标志、人行道、围栏、标杆、墙、建筑、植被、车辆、行人和其他。

CARLA支持自动驾驶系统的开发、训练和详细的性能分析。我们使用CARLA评估了三种自动驾驶方法。第一种是一种modular pipeline，它依赖于视觉感知、规划和控制的专用子系统。这种结构符合大多数现有的自动驾驶系统[21,8]。第二种方法基于通过模拟学习进行端到端训练的深度网络[4]。这种方法最近引起了新的兴趣[22，16，4]。第三种方法基于通过强化学习进行端到端训练的深度网络[19]。

3.1 modular pipeline

我们的第一种方法是一个modular pipeline，它将驾驶任务分解到以下子系统中：（i）感知；（ii）规划；（iii）持续控制。由于没有提供几何地图作为输入，视觉感知成为一项关键任务。局部规划完全依赖于感知模块估计的场景布局。

感知部分使用语义分割来估计车道、道路限制、动态对象和其他危险。此外，还使用分类模型来确定交叉口的接近度。规划器使用基于规则的状态机。持续控制由PID控制器执行，该控制器驱动转向、节气门和制动机构。现在我们将更详细地描述这些模块。

感知。我们在这里描述的感知是建立在基于RefineNet的语义分割网络上的[17]。训练网络将图像中的每个像素分为以下语义类别之一：C=froad、sidewalk、lane marking、dynamic object、misscellaneous staticg。该网络使用CARLA在训练环境中生成的2500张标注图像进行训练。根据道路面积和车道标线，利用网络提供的概率分布来估算车道。

此外，我们使用基于AlexNet的二元场景分类器（交叉/无交叉）来估计到达交叉路口的可能性[15]。这个网络是在两个类之间平衡的500幅图像上训练的。

规划器。规划器通过生成一组路径点来实现低级别导航：近期目标状态表示车辆在不久的将来所需的位置和方向。规划器的目标是合成使汽车保持在道路上并防止碰撞的路径点。规划器基于状态机，状态机具有以下状态：（i）道路跟随，（ii）左转，（iii）右转，（iv）交叉路口向前和（v）危险停车。状态之间的转换基于感知模块提供的估计值和全局规划器提供的拓扑信息来执行。路径点连同车辆当前的姿态和速度一起传送给控制器。

持续控制器。我们使用比例-积分-微分（PID）控制器[6]，因为它简单、灵活，并且对慢响应时间具有相对的鲁棒性。每个控制器接收当前姿态、速度和路径点列表，并分别驱动转向、油门和制动机构。我们的目标巡航速度为20公里/小时。

3.2 模仿学习

我们的第二种方法是条件模仿学习，这是一种除了感知输入外还使用高级命令的模拟学习[4]。该方法利用城镇中人类驾驶员记录的一个驾驶轨迹数据集。Thedataset D = fhoi; ci; aiig consists of tuples, each of which contains anobservation oi, a command ci, and an action ai. 这些命令由驾驶员在数据采集过程中提供，并指示他们的意图，类似于转向信号灯。我们使用一组四个命令：沿车道行驶（默认），在下一个十字路口直行，在下一个十字路口左转，在下一个十字路口右转。观察结果是来自前向摄像机的图像。为了提高学习策略的鲁棒性，我们在数据采集过程中加入了噪声。

我们已经收集了大约14个小时的驾驶数据用于训练。使用Adam优化器对网络进行训练[14]。为了提高泛化能力，我们进行了数据扩充和删除。

3.3 强化学习

我们的第三种方法是深度强化学习，它基于环境提供的奖励信号训练一个深度网络，没有人类驾驶轨迹。我们使用A3C[19]。该算法在仿真的三维环境中表现良好，例如赛车[19]和三维迷宫中的导航[19,13,5]。该方法的异步特性使多个线程能够并行运行，这对于深度强化学习的高样本复杂度非常重要。

我们训练A3C进行目标导向的导航。在每一次训练中，车辆必须在拓扑规划器的高级命令指导下达到目标。当车辆到达目标时，当车辆与障碍物相撞时，或当时间预算用尽时，事件终止。奖励是五项的加权和：朝目标行驶的速度和距离（正加权）、碰撞（负加权）、与人行道重叠（负加权）、与对面车道重叠（负加权）。

该网络使用10个并行线程进行训练，总共进行1000万个simulation steps。因为仿真所带来的计算成本，我们将训练限制在1000万个simulation steps。这相当于以每秒10帧的速度连续驾驶12天。


4 实验
我们评估了三种方法——模块化流水线（MP）、模拟学习（IL）和强化学习（RL），在六种天气条件下，在两个可用城镇中的每一个进行四项越来越困难的驾驶任务。我们按照增加难度的顺序组织任务如下：

•直线：目的地位于起点正前方，环境中没有动态对象。到目标的平均行驶距离，Town1为200米，Town 2为100米。

•一个转弯：目的地离出发点只有一个转弯；没有动态物体。到目标的平均行驶距离, Town1为400米，Town 2为170米。

•导航：不限制目的地相对于起点的位置，无动态物体。到目标的平均行驶距离, Town1为170米，Town 2为360米。

•存在动态障碍物的导航：与上一个任务相同，但使用动态对象（汽车和行人）。

实验在两个城镇进行。Town1用于培训，Town2用于测试。我们考虑六种天气条件进行实验，分成两组。训练用的天气集包括晴天、晴朗的日落、下雨的白天和雨后的白天。测试集的天气是训练集不包含的，包括多云的白天和细雨的日落。

对于一个任务、一个城镇和一个天气集合的每一个组合，都要进行超过25次的测试。在每一次测试中，目标是到达指定的目标位置。如果在预定时间内达到目标，则认为事件成功。预定时间为以10 km/h的速度沿着最佳路径达到目标所需的时间。违规行为：如在人行道上驾驶或产生碰撞，不会导致事件终止，但会记录和报告。

结果表明了几个一般性结论。总的来说，即使是在最简单的直线驾驶任务中，所有方法的性能都不完美，对于更困难的任务，成功率进一步下降。对新天气的泛化要比对一个新城镇的泛化容易得多。模块化流水线和模拟学习在大多数任务和条件下都能达到同等水平。强化学习相对于其他两种方法表现不佳。现在我们将更详细地讨论这四个关键发现。

四项任务的表现。令人惊讶的是，在训练条件下，即使是在空旷的街道上笔直行驶这一最简单的任务，也没有一种方法能完美地发挥作用。我们认为，这一现象的根本原因是：输入的可变性。训练条件包括四种不同的天气条件。在训练过程中的精确轨迹不会在测试中重现。因此，完美地完成这项任务需要鲁棒的泛化，这对现有的深度学习方法是有挑战的。

对于更高级的任务，所有方法的性能都会下降。在人口稠密的城市环境中的导航任务，两种最好的方法（模块化流水线和模拟学习）在所有条件下的成功率都低于90\%。这些结果清楚地表明，即使在训练条件下，性能也远未达到饱和，并且在新环境下的泛化是一个严重的挑战。

泛化。我们研究两种类型的泛化：对以前没遇到的天气条件和以前没遇到的环境。有趣的是，这两者的结果截然不同。对于模块化流水线和模拟学习来说，“新天气”条件下的性能与训练条件下的性能非常接近，有时甚至更好。然而，推广到一个新城镇对这三种方法都提出了挑战。在两个最具挑战性的导航任务中，当切换到测试城镇时，所有方法的性能下降了很多。这种现象可以解释为这样一个事实，即模型已经在多种天气条件下训练，但只在一个城镇训练。不同天气下的训练结果可以支持对以前没遇到的天气进行泛化，但对使用不同纹理和3D模型的新城镇则不适用。通过在不同的环境中进行训练，这个问题可能会得到改善。总的来说，我们的结果强调了泛化对基于学习的感觉运动控制方法的重要性。

模块化流水线vs端到端学习。分析模块化流水线和模拟学习方法的相对性能具有一定的指导意义。令人惊讶的是，在大多数测试条件下，这两种系统的性能非常接近：这两种方法的性能相差不到10\%。这个结论有两个例外：一是模块化流水线在“新天气”条件下比在训练条件下表现更好。这是由于训练和测试天气的特定选择：感知系统恰好在测试天气下表现更好。另一个是，模块化流水线在“新城镇”条件下的导航任务表现不佳，在“新城镇和新天气”下的直线任务表现不佳。这是因为感知算法在新环境的复杂天气条件下系统性地失效。如果感知算法无法可靠地找到可驾驶路径，则基于规则的规划器和经典控制器将无法以一致的方式导航到目的地。因此，如果感知算法正常工作，整个系统工作正常；否则它将完全失败。从这个意义上说，模块化流水线比端到端方法更脆弱。

模仿学习与强化学习。我们现在对比两个端到端训练系统的表现：模仿学习和强化学习。在所有任务中，强化学习训练的表现都比模仿学习的要差。尽管如此，强化学习的训练使用的数据量要大得多：强化学习的数据是驾驶12天的，而模仿学习的仅是14小时的。为什么这一次强化学习表现不佳，而在Atari游戏[18,19]和迷宫导航[19,5]等任务上取得了很好的成绩？一个原因是众所周知强化学习是脆弱的[12]，并且it is common to perform extensivetask-specific hyperparameter search，例如Mnih等人报告的每个环境50次试验[19] 。当使用模拟器时，这种extensive hyperparameter search变得不可行。我们根据文献证据和迷宫导航的探索性实验选择hyperparameters。另一种解释是，城市驾驶比以前用强化学习解决的大多数任务更困难。例如，与迷宫导航相比，在驾驶场景中必须处理混乱动态环境中的车辆动态和更复杂的视觉感知。最后，强化学习泛化能力差的原因可能是：与模拟学习相比，强化学习的训练没有数据扩充或规则化。

违规分析。CARLA支持驾驶策略的细粒度分析。现在，我们将研究三个系统在最困难的任务上的行为：存在动态对象的导航。我们通过以下五种违规行为中任意两种行为之间的平均行驶距离来评价这三个系统：在相反车道上行驶、在人行道上行驶、与其他车辆相撞、与行人相撞和撞击静止物体。

\section{更多技术支持}
交通场景指的是交通参与者在仿真世界中多样的动态行为，通过这些动态行为对运行在其中的自动驾驶车辆进行充分测试。交通场景的丰富性依赖于交通参与者的种类和其能实现的动态行为，CARLA支持轿车、SUV、客车、卡车、摩托车、自行车、行人等多种动态参与者及锥桶、售货机等多种静态参与者，动态参与者的行为可通过预先定义的场景和在线运行的交通流来控制。

CARLA中的交通管理器（Traffic Manager）模块可进行场景和交通流的模拟，不过鉴于基于OpenSCENARIO格式的场景仿真更通用，我们选用CARLA提供的场景运行器（ScenarioRunner，以下简称SR）来进行场景的模拟。下面对SR的安装和使用进行说明。

01. ScenarioRunner的安装
ScenarioRunner是由CARLA官方提供的、与CARLA配合使用的场景解析和运行工具，支持CARLA自定义的scenario格式、route格式和OpenSCENARIO格式等多种预定义场景文件的运行，本书主要使用其OpenSCENARIO场景运行功能。OpenSCENARIO目前已经发布1.2和2.0版本，其中1.0和2.0版本都在ScenarioRunner中得到了支持。

OpenSCENARIO是德国自动化及测量系统标准协会ASAM提供的一个描述动态场景的标准格式，关于OpenSCENARIO格式的内容，大家可以看下之前对OpenSCENARIO的格式介绍和实例分析。

SR的安装步骤如下：

（1）下载源码

SR的github上提供了与CARLA版本相配合的Release版本[ https://github.com/carla-simulator/scenario\_runner/releases]，如SR0.9.13与CARLA 0.9.13相配合。这是因为SR需要使用PythonAPI从CARLA获取信息并对CARLA中的交通参与者、天气等进行控制，如果版本不匹配的话会操作失败。为了获取最新的特性，我们这里使用下载源码的方式进行安装。

大家可以选择将SR下载到任何位置，为了方便起见这里下载到CARLA文件夹下。

\$ cd /path/to/carla
\$ git clone https://github.com/carla-simulator/scenario\_runner.git
（2）依赖库安装

进入scenario\_runner文件夹，并根据其中的requirements.txt安装依赖库：

\$ cd scenario\_runner
\$ sudo apt remove python3-networkx \#若安装过networkx则先将其卸载
\$ pip3 install -r requirements.txt
按照以上步骤安装依赖后，若本地numpy版本高于1.20，运行时可能有包含如下字符的报错：......networkx/readwrite/graphml.py......module 'numpy' has no attribute 'int'...... 。这是因为requirements.txt中指定的networkx 2.2版本使用了http://np.int，该用法在nump 1.20版本以上已经不再支持。读者可以根据实际情况安装高版本networkx或者低版本的numpy。

\#\#以下两种方法选一即可
\#1.卸载networkx，并重新安装新版本
\$ pip3 uninstall networkx
\$ pip3 install networkx
\#2.卸载numpy，并重新安装低版本
\$ pip3 uninstall numpy
\$ pip3 install numpy==1.20
（3）设置环境变量

为了在运行时能够找到相关的文件，需要设置一些环境变量。打开~/.bashrc文件，并在其结尾加入如下内容：

export CARLA\_ROOT=/path/to/carla
export SCENARIO\_RUNNER\_ROOT=\$CARLA\_ROOT/scenario\_runner
export PYTHONPATH=\$PYTHONPATH:\$CARLA\_ROOT/PythonAPI/carla
大家请注意将其中路径修改为自己电脑上的实际路径，然后运行source ~/.bashrc使设置生效。

至此用于运行OpenSCENARIO 1.0文件（以下简称xosc文件）的安装工作都已完成，大家可尝试按照下一节的方法运行相关文件。若想运行OpenSCENARIO 2.0文件（以下简称osc文件），还需要进行如下操作。

（4）安装OpenSCENARIO 2.0相关依赖

\# 安装JDK
\$ sudo apt install openjdk-17-jdk
\# 安装Antlr
\$ curl -O https://www.antlr.org/download/antlr-4.10.1-complete.jar
\$ sudo cp antlr-4.10.1-complete.jar /usr/local/lib/
\$ pip3 install antlr4-python3-runtime==4.10
打开~/.bashrc文件，并在其结尾加入如下内容，然后运行source ~/.bashrc使设置生效。

export CLASSPATH=".:/usr/local/lib/antlr-4.10.1-complete.jar:\$CLASSPATH"
alias antlr4='java -jar /usr/local/lib/antlr-4.10.1-complete.jar'
alias grun='java org.antlr.v4.gui.TestRig'xport CARLA\_ROOT=/path/to/carla
export SCENARIO\_RUNNER\_ROOT=\$CARLA\_ROOT/scenario\_runner
export PYTHONPATH=\$PYTHONPATH:\$CARLA\_ROOT/PythonAPI/carla
02.运行OpenSCENARIO文件
使用SR运行xosc/osc文件的步骤十分简单，首先启动CARLA，然后运行SR并指定xosc/osc文件即可：

（1）启动CARLA：

\$ cd /path/to/carla
\$ ./CarlaUE4.sh
（2）配置ego车

实际测试时应由被测算法控制ego车，此处为了进行演示，通过SR自带的manual\_control.py为ego车配置自动驾驶：

\$ cd /path/to/scenario\_runner
\# 加载xosc文件示例时使用
\$ python3 manual\_control.py  -a
\# 加载osc文件示例时使用
\$ python3 manual\_control.py  -a --rolename ego\_vehicl
需要注意的是，manual\_control.py根据rolename查找ego车辆并为其配置自动驾驶，默认ego车辆的rolename为“hero”，在下面的xosc文件示例中ego车辆的rolename恰好为“hero”，故无需配置“--rolename”参数，而osc文件示例中ego车辆的rolename为“ego\_vehicle”，从而需要指定“--rolename”。

（3）运行ScenarioRunner

\$ cd /path/to/scenario\_runner
\# 运行xosc文件示例
\$ python3 scenario\_runner.py --output --openscenario srunner/examples/FollowLeadingVehicle.xosc
\# 运行osc文件示例
\$ python3 scenario\_runner.py --outpu --openscenario2 srunner/examples/cut\_in\_and\_slow\_range.osc
运行上述命令后，可以在CARLA渲染窗口中观察到地图根据xosc文件中定义变更，同时生成了ego车和其前方的障碍车。
\newpage

\section{总结与展望}

\subsection{总结}
自动驾驶汽车技术发展需科学测试体系支持。虚拟仿真测试是解决封闭和开放道路测试成本和效率问题的有效方法，尽管理论和技术体系待完善。数字虚拟仿真在生成危险场景方面具有明显优势，是提升测试安全性和可靠性的关键，正成为研究焦点。

现有的自动驾驶危险场景生成方法包括专家经验法、自然驾驶数据提取法、危险场景衍生法和基于强化学习的自生成法。专家经验法主观且难以覆盖所有场景，自然驾驶数据提取法缺乏动态交互能力，危险场景衍生法可能产生不真实的轨迹。这些方法多限于学术研究，难以应用于工程实践。基于强化学习的自生成法能实时修正场景状态，生成定制化场景库，适合高级别自动驾驶测试，成为研究热点。但现有方法可能产生不自然或重复场景，缺乏泛化能力。本项目旨在设计一种综合自然性、对抗性和多样性的统一生成策略，解决现有方法在实际应用中的不足。

为了探索自动驾驶汽车的性能极限，评估自动驾驶系统的安全性、可靠性和可信度，这需要精确且完整地描述自动驾驶的性能边界。现有的研究未使用真实的自动驾驶模型和算法进行性能边界的挖掘，这可能导致缺乏现实性、误导性结果和可迁移性问题。同时，现有的研究仅考虑周围车辆产生危险行为会限制对整体风险的评估。因为行人和环境因素可能引入新的风险和挑战，需要在危险场景生成中进行考虑。忽略这些因素可能导致对风险的低估，无法全面评估自动驾驶系统在复杂和多变环境中的行为和决策能力。当前研究仅仅利用背景车辆的初始运行条件(位置、速度、航向角等)来构造驾驶场景的参数空间，因此更加高维的参数空间应该被定义以精细化和全面地表征自动驾驶性能边界。当处理高维参数空间和昂贵的自动驾驶仿真评价时，通用的启发式智能优化算法往往将不再适用，能进行有效求解的优化算法非常有限。在这种情况下，非常有必要借助代理建模、最优计算资源分配、样本填充策略等技术设计相应的随机或鲁棒仿真优化算法，这也是本项目研究的关键点。

作为当前世界最先进的自动驾驶方案，端到端自动驾驶具有较强的感知性能和泛化能力，构建的自动驾驶系统更加简单智能。然而现有的端到端自动驾驶决策方法还存在以下问题：1）端到端自动驾驶模型依赖训练数据，面对复杂和危险场景时可能做出不合理决策；2）端到端自动驾驶依赖深度神经网络，这些网络的黑盒特性使得决策过程难以解释，限制了系统行为的理解和调试；3）端到端自动驾驶模型从图像或点云直接输出控制信号，训练中难以全面理解复杂交通环境，无法考虑车辆互动、行人、信号灯等多重因素，导致决策缺乏适应性和灵活性。为端到端自动驾驶设计一个富含驾驶语义信息的输入，并利用先进的神经网络架构突破以往自动驾驶的性能边界是本研究的终极目标。

本研究紧密围绕自动驾驶场景生成与安全评估的核心问题，深入探索并提出 ChatScene 与 ASIL-Gen 协同解决方案，成功构建起从场景高效生成到精准风险评估的完整技术体系，为自动驾驶测试领域带来了创新性突破。​
在场景生成层面，ChatScene 框架展现出独特的技术优势。其创新性地融合 Scenic 语言、深度强化学习与 GPT-4o 模型，实现了场景生成模式的多元化与智能化。在固定场景模式下，基于 Scenic 语言预定义的 8 类基准场景，涵盖城市主干道、高速公路、乡村道路等多种典型交通环境，通过深度强化学习中的 SAC 算法，以碰撞避免、车道保持、速度优化等为核心奖励函数，对场景中对抗行为参数进行精细化调整与优化，从而模拟出高度真实、复杂多变的交通参与者交互行为，为自动驾驶系统提供标准化、规范化的测试场景模板。在动态模式方面，借助 GPT-4o 强大的自然语言理解与代码生成能力，用户仅需输入自然语言描述，如 “暴雨天气下，自我车辆在无信号灯十字路口左转，对向车辆突然加速直行”，系统便能快速解析语义信息，并将其转化为符合 CARLA 0.9.13 规范的场景代码。通过设定详细的约束条件，包括道路类型、车辆动力学参数、交通规则等，生成多样化、贴近真实驾驶场景的测试用例，相比传统基于 LiDARGen 的场景生成方法，动态模式的生成效率提升了 107 倍，极大地丰富了自动驾驶测试场景的多样性与灵活性，显著提高了测试效率。​

在安全评估领域，ASIL-Gen 发挥了关键作用。该模块通过 NSGA-II 多目标优化算法与基于 ISO 26262 标准的量化评估模型，实现了场景的优化筛选与科学分类。在场景生成阶段，基于基础场景模板，通过脚本自动化生成 13 类场景变体，包括动态障碍物交叉、无信号路口冲突、恶劣天气下的跟车等复杂情况，并通过调整障碍物位置、速度、交通流量等参数，形成海量多样化的测试场景。在此基础上，利用 NSGA-II 算法，以碰撞概率与场景复杂度作为双目标函数进行优化。碰撞概率通过精确预测车辆、行人等交通参与者的运动轨迹进行计算，场景复杂度则综合考虑交通参与者数量、道路拓扑结构、环境干扰因素等多个指标，从而搜索出帕累托前沿，筛选出既具有高风险价值又具备代表性的场景。实验数据显示，通过 ASIL-Gen 优化后，高风险 ASIL-D 等级场景占比从随机搜索的 5\% 提升至 12\%，经过进一步优化后更是提升至 15\%，显著增强了场景筛选的精准性与安全评估的科学性。​

在实验验证环节，本研究取得了一系列具有说服力的成果。基于 ChatScene 训练的 RL 模型在行人横穿场景测试中，与基线模型进行多次重复对比实验，通过精确统计碰撞次数，结果表明其碰撞率降低了 32\%，充分验证了 ChatScene 与 ASIL-Gen 协同方案对提升自动驾驶系统鲁棒性的有效性。同时，在场景生成效率、安全评估准确性等方面的实验数据，均有力地证明了该方案在自动驾驶技术安全测试中的巨大应用价值，为自动驾驶技术的安全测试开辟了新的技术路径与研究方向。

安全模型，英伟达的安全力场（SFF）和Mobileye的责任敏感安全（RSS）等对决策来说是有可解释性的数学模型。这项工作从头开始实现SFF，替代未公开的英伟达源代码，并将其与CARLA开源模拟器集成。使用SFF和CARLA，提出了一个车辆声明集合的预测器，并以此提出一种综合驾驶策略，无论在通过动态交通时遇到什么安全条件，其都能持续运行。该策略没有针对每种情况制定单独的规划，但利用安全潜能，目的是将类人的驾驶融入交通流中。



责任敏感安全（RSS）将自车的危险时间t与纵向/横向的危险阈值时间tlong/tlat进行比较。如果达到阈值，RSS判断为危险情况，并根据纵向或横向加速度对速度的限制做出适当的响应。换句话说，阈值可以用轨迹集的多边形表示。如果自车和其他道路使用者之间的轨迹集相交，RSS会选择以下三个决策中的一个来恢复安全状态：刹车，继续前进或开车离开。

安全力场（SFF）表示，如果参与者遵循安全程序（这是一系列控制策略），量化风险的安全潜能ρAB不会再增加，因此可以保证参与者最终不会造成不安全的情况。这可以通过安全潜能的链式法则从数学上证明。简而言之，RSS的方法是最小化参与者声称集合之间的交集，这是每个参与者安全程序产生轨迹的联合。

英特尔发布了一个名为ad-rss-lib的开源库，该库部分实现了RSS。此外，NVIDIA还提供了一个名为DriveWorks SDK的软件开发工具包，其中包括针对经批准用户的SFF实现。Intel ad-rss-lib没有涵盖其论文的全部范围，但它提供了Python绑定和CARLA集成。然而，NVIDIA DriveWorks SDK是一个非公开IP，它的实现是为了与配备NVIDIA DRIVE OS的NVIDIA DRIVE平台集成，因此研究人员很少使用它。在Intel和NVIDIA建议的将RSS和SFF与现有自动驾驶系统集成的基本示例架构中，RSS和SFF扮演着最后的角色，通过重写规划子系统的决策来防止自动驾驶车辆发生碰撞。

在SFF实施中使用声明集合和安全潜能的概念，声明集合就是安全程序（驾驶策略）获取的轨迹之联合，安全潜能是两个参与者的声明集合之间相交测度及其负梯度。该文提出了一种将SFF集成到规划子系统中的方法，制定一种类似人类的驾驶策略，无论在安全或不安全的条件下都能始终如一地运行，最终尽量不阻碍顺畅的交通流。

Intel RSS或NVIDIA SFF作为与现有子系统协调的附加模块。它接收来自感知子系统的世界环境数据和来自规划子系统的机动决策。为了自车的安全，作为上层限制器，它可以推翻接收的决策，并将限制的决策传递给驾驶子系统。如图是具有RSS或SFF安全模型的基本示例架构：灰色是现有子系统部分，蓝色/绿色是附加模块的RSS/SFF实现部分。

\subsection{展望}


尽管本研究在自动驾驶场景生成与安全评估领域取得了一定成果，但面对自动驾驶技术快速发展的需求与挑战，该领域仍存在诸多亟待深入探索的方向，未来研究可从以下多个维度展开：​

深化多模态数据融合：目前，自动驾驶场景生成主要依赖有限的数据源，未来研究将进一步深化多模态数据融合。除了继续探索激光雷达、摄像头数据的深度融合外，还将引入毫米波雷达数据，利用其在恶劣天气下的稳定探测性能，提升场景中目标检测与跟踪的准确性；同时融合高精地图数据，将地图中的道路属性、交通标志、车道线等信息与传感器数据相结合，构建更贴近真实驾驶环境的场景生成模型。通过多模态数据的协同处理与特征融合，不仅能够提升场景的物理真实性，还能增强场景的语义准确性，使生成的场景更符合实际驾驶过程中的复杂情况，为自动驾驶系统提供更具挑战性与真实性的测试环境。​

拓展 ASIL 分类标准：现有的 ASIL 分类标准主要基于静态的交通场景因素，未来将结合车路协同、交通流理论等前沿技术，对其进行拓展与完善。将 V2X 通信状态纳入评估体系，考虑车辆与车辆、车辆与基础设施之间的信息交互对驾驶安全的影响；同时引入交通拥堵态势分析，结合交通流模型，评估不同拥堵程度下自动驾驶系统面临的风险。此外，还将探索驾驶员行为模型与 ASIL 分类的结合，分析人类驾驶行为的不确定性对自动驾驶系统安全的潜在影响，从而完善高风险场景的识别维度，使 ASIL 分类标准更全面、准确地反映自动驾驶系统在复杂交通环境下的安全风险状况。​

探索模型轻量化与实时化：随着自动驾驶技术向边缘设备的不断渗透，算力受限成为制约实时在线评估的关键因素。未来研究将致力于探索 ChatScene 与 ASIL-Gen 算法架构的轻量化与实时化优化。一方面，通过模型压缩技术，如剪枝、量化等方法，减少模型参数与计算量；另一方面，采用高效的算法优化策略，如改进的神经网络结构、并行计算技术等，提高算法执行效率。针对边缘设备的硬件特性，开发专用的轻量化模型，使其能够在资源有限的条件下快速生成场景并进行安全评估，推动自动驾驶仿真测试从离线分析向实时在线评估方向发展，为自动驾驶车辆的实时决策与安全监控提供有力支持，加速自动驾驶技术的落地应用进程。​

强化人机协同测试模式：考虑到自动驾驶系统最终服务于人类出行，未来可探索将人类驾驶员的行为与决策纳入测试体系，构建人机协同的测试模式。通过收集和分析人类驾驶数据，模拟不同驾驶风格、驾驶习惯的人类驾驶员与自动驾驶系统的交互场景，评估自动驾驶系统在人机共驾环境下的安全性与适应性。同时，研究如何利用人类驾驶员的经验与直觉，辅助自动驾驶系统进行决策，实现人机优势互补，进一步提升自动驾驶系统的可靠性与用户接受度。​

开展跨地域与跨文化场景研究：目前的研究主要基于特定地域的交通规则与驾驶习惯，未来将开展跨地域与跨文化场景研究。收集不同国家、不同地区的交通数据，分析其交通规则、驾驶文化的差异，构建多样化的跨地域场景库。通过在这些场景下对自动驾驶系统进行测试与评估，确保自动驾驶技术在全球范围内的适用性与安全性，推动自动驾驶技术的全球化发展。







\newpage



