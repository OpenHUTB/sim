\%!TEX root = ../../csuthesis\_main.tex

\chapter{技术实现}

\section{技术支持}

\subsection{技术实现要素}
多传感器融合的环境感知系统
智能驾驶车辆依靠多传感器融合的环境感知系统，通过融合激光雷达、毫米波雷达、摄像头等多种传感器，来实现对周围环境的全面感知，这种多传感器融合技术能够提供更精准信息。 ​


高精度地图与定位技术
高精度地图搭配实时定位技术（像RTK、IMU这类）为智能驾驶车辆提供精确位置信息和道路元素数据，这种技术能够支持车辆在复杂道路环境当中进行行驶的精确导航和路径规划，确保行驶安全。 ​


多模态大模型AI安全员
把多模态大模型引入当作AI安全员，可实时处理来自摄像头的图像数据，识别车辆行驶过程中碰到的危险场景与异常情况，这种AI安全员具备跨模态理解能力，能应对传统算法难以覆盖的长尾场景，像不规则路面和临时施工区域等，提升系统的安全性和鲁棒性。 ​


虚拟现实技术的仿真系统
利用虚拟现实技术构建的仿真系统，可以模拟各种驾驶场景，包括电子设备故障、系统功能局限、人员误操作等安全威胁。​通过三维建模和实时渲染，渲染能营造出十分逼真的虚拟驾驶环境，主要用于测试和优化智能驾驶系统响应能力。

异常处理与自适应错误修复机制
在智能驾驶过程中系统有可能碰到各类异常状况，像传感器失效或者算法参数设置不合理等情况，所以系统得具备异常处理和自适应错误修复机制，可识别错误状态并采取对应调整策略保证车辆安全运行。

多传感器融合的环境感知系统
智能驾驶车辆借助融合多种传感器来达成对周围环境全面感知，比如激光雷达、毫米波雷达以及摄像头等，这种多传感器融合技术能够提供360度的视野，实时检测并跟踪周围的交通参与者和障碍物，为决策和规划模块提供准确的环境信息。 ​

高精度地图与定位技术
高精度地图搭配实时定位技术（像RTK、IMU这类）给智能驾驶车辆提供精确位置信息与道路元素数据，这种技术能够支持车辆在复杂道路环境中的精确导航和路径规划，确保行驶安全。 ​

多模态大模型AI安全员
把多模态大模型引入当作AI安全员，可实时处理来自摄像头的图像数据，识别车辆行驶过程中碰到的危险场景与异常情况，该AI安全员具备跨模态理解能力，能应对传统算法难以覆盖的长尾场景，像不规则路面、临时施工区等，提升系统的安全性和鲁棒性。 ​

虚拟现实技术的仿真系统
利用虚拟现实技术构建的仿真系统，可以模拟各种驾驶场景，包括电子设备故障、系统功能局限、人员误操作等安全威胁。​通过三维建模和实时渲染，提供逼真的虚拟驾驶环境，用于测试和优化智能驾驶系统的响应能力。 ​

异常处理与自适应错误修复机制
在智能驾驶的过程当中系统可能会碰到各类异常状况，像传感器出现失效或者算法参数设置得不合理等，为此系统需要拥有异常处理以及自适应错误修复机制，可识别错误状态并且采取对应的调整策略来确保车辆持续安全运行\cite{朱西产2019安全切入场景下的驾驶人初始制动时刻分析}。



\section{更多技术支持}
交通场景指的是交通参与者在仿真世界中多样的动态行为，通过这些动态行为对运行在其中的自动驾驶车辆进行充分测试。交通场景的丰富性依赖于交通参与者的种类和其能实现的动态行为，CARLA支持轿车、SUV、客车、卡车、摩托车、自行车、行人等多种动态参与者及锥桶、售货机等多种静态参与者，动态参与者的行为可通过预先定义的场景和在线运行的交通流来控制。

CARLA中的交通管理器（Traffic Manager）模块可进行场景和交通流的模拟，不过鉴于基于OpenSCENARIO格式的场景仿真更通用，我们选用CARLA提供的场景运行器（ScenarioRunner，以下简称SR）来进行场景的模拟。下面对SR的安装和使用进行说明。

01. ScenarioRunner的安装
ScenarioRunner是由CARLA官方提供的、与CARLA配合使用的场景解析和运行工具，支持CARLA自定义的scenario格式、route格式和OpenSCENARIO格式等多种预定义场景文件的运行，本书主要使用其OpenSCENARIO场景运行功能。OpenSCENARIO目前已经发布1.2和2.0版本，其中1.0和2.0版本都在ScenarioRunner中得到了支持。

OpenSCENARIO是德国自动化及测量系统标准协会ASAM提供的一个描述动态场景的标准格式，关于OpenSCENARIO格式的内容，大家可以看下之前对OpenSCENARIO的格式介绍和实例分析。

SR的安装步骤如下：

（1）下载源码

SR的github上提供了与CARLA版本相配合的Release版本[ https://github.com/carla-simulator/scenario\_runner/releases]，如SR0.9.13与CARLA 0.9.13相配合。这是因为SR需要使用PythonAPI从CARLA获取信息并对CARLA中的交通参与者、天气等进行控制，如果版本不匹配的话会操作失败。为了获取最新的特性，我们这里使用下载源码的方式进行安装。

大家可以选择将SR下载到任何位置，为了方便起见这里下载到CARLA文件夹下。

\$ cd /path/to/carla
\$ git clone https://github.com/carla-simulator/scenario\_runner.git
（2）依赖库安装

进入scenario\_runner文件夹，并根据其中的requirements.txt安装依赖库：

\$ cd scenario\_runner
\$ sudo apt remove python3-networkx \#若安装过networkx则先将其卸载
\$ pip3 install -r requirements.txt
按照以上步骤安装依赖后，若本地numpy版本高于1.20，运行时可能有包含如下字符的报错：......networkx/readwrite/graphml.py......module 'numpy' has no attribute 'int'...... 。这是因为requirements.txt中指定的networkx 2.2版本使用了http://np.int，该用法在nump 1.20版本以上已经不再支持。读者可以根据实际情况安装高版本networkx或者低版本的numpy。

\#\#以下两种方法选一即可
\#1.卸载networkx，并重新安装新版本
\$ pip3 uninstall networkx
\$ pip3 install networkx
\#2.卸载numpy，并重新安装低版本
\$ pip3 uninstall numpy
\$ pip3 install numpy==1.20
（3）设置环境变量

为了在运行时能够找到相关的文件，需要设置一些环境变量。打开~/.bashrc文件，并在其结尾加入如下内容：

export CARLA\_ROOT=/path/to/carla
export SCENARIO\_RUNNER\_ROOT=\$CARLA\_ROOT/scenario\_runner
export PYTHONPATH=\$PYTHONPATH:\$CARLA\_ROOT/PythonAPI/carla
大家请注意将其中路径修改为自己电脑上的实际路径，然后运行source ~/.bashrc使设置生效。

至此用于运行OpenSCENARIO 1.0文件（以下简称xosc文件）的安装工作都已完成，大家可尝试按照下一节的方法运行相关文件。若想运行OpenSCENARIO 2.0文件（以下简称osc文件），还需要进行如下操作。

（4）安装OpenSCENARIO 2.0相关依赖

\# 安装JDK
\$ sudo apt install openjdk-17-jdk
\# 安装Antlr
\$ curl -O https://www.antlr.org/download/antlr-4.10.1-complete.jar
\$ sudo cp antlr-4.10.1-complete.jar /usr/local/lib/
\$ pip3 install antlr4-python3-runtime==4.10
打开~/.bashrc文件，并在其结尾加入如下内容，然后运行source ~/.bashrc使设置生效。

export CLASSPATH=".:/usr/local/lib/antlr-4.10.1-complete.jar:\$CLASSPATH"
alias antlr4='java -jar /usr/local/lib/antlr-4.10.1-complete.jar'
alias grun='java org.antlr.v4.gui.TestRig'xport CARLA\_ROOT=/path/to/carla
export SCENARIO\_RUNNER\_ROOT=\$CARLA\_ROOT/scenario\_runner
export PYTHONPATH=\$PYTHONPATH:\$CARLA\_ROOT/PythonAPI/carla
02.运行OpenSCENARIO文件
使用SR运行xosc/osc文件的步骤十分简单，首先启动CARLA，然后运行SR并指定xosc/osc文件即可：

（1）启动CARLA：

\$ cd /path/to/carla
\$ ./CarlaUE4.sh
（2）配置ego车

实际测试时应由被测算法控制ego车，此处为了进行演示，通过SR自带的manual\_control.py为ego车配置自动驾驶：

\$ cd /path/to/scenario\_runner
\# 加载xosc文件示例时使用
\$ python3 manual\_control.py  -a
\# 加载osc文件示例时使用
\$ python3 manual\_control.py  -a --rolename ego\_vehicl
需要注意的是，manual\_control.py根据rolename查找ego车辆并为其配置自动驾驶，默认ego车辆的rolename为“hero”，在下面的xosc文件示例中ego车辆的rolename恰好为“hero”，故无需配置“--rolename”参数，而osc文件示例中ego车辆的rolename为“ego\_vehicle”，从而需要指定“--rolename”。

（3）运行ScenarioRunner

\$ cd /path/to/scenario\_runner
\# 运行xosc文件示例
\$ python3 scenario\_runner.py --output --openscenario srunner/examples/FollowLeadingVehicle.xosc
\# 运行osc文件示例
\$ python3 scenario\_runner.py --outpu --openscenario2 srunner/examples/cut\_in\_and\_slow\_range.osc
运行上述命令后，可以在CARLA渲染窗口中观察到地图根据xosc文件中定义变更，同时生成了ego车和其前方的障碍车。
\newpage

\section{总结与展望}

\subsection{总结}
自动驾驶汽车技术的发展需要科学测试体系来提供支持，虚拟仿真测试是解决封闭和开放道路测试成本与效率问题的有效办法，虽说其理论和技术体系还有待完善，数字虚拟仿真在生成危险场景方面具备明显优势，是提升测试安全性和可靠性的关键所在，正逐渐成为研究的焦点，现有的自动驾驶危险场景生成方法包含专家经验法、自然驾驶数据提取法、危险场景衍生法以及基于强化学习的自生成法，专家经验法比较主观且难以覆盖所有场景情况，自然驾驶数据提取法缺乏动态交互能力，危险场景衍生法可能会产生不真实的轨迹，这些方法大多局限于学术研究难以应用到工程实践当中，基于强化学习的自生成法能够实时修正场景状态生成定制化场景库，适合高级别自动驾驶测试从而成为研究热点，不过现有方法可能产生不自然或者重复的场景且缺乏泛化能力，本项目旨在设计一种综合自然性、对抗性和多样性的统一生成策略以解决现有方法在实际应用中的不足 \cite{石娟2017行人自动紧急制动系统测试评价方法研究}。

为了探索自动驾驶汽车性能方面的极限情况，评估自动驾驶系统安全性、可靠性和可信度，需要精确且完整地描述自动驾驶性能边界，现有的研究没有使用真实自动驾驶模型和算法挖掘性能边界，可能导致缺乏现实性、出现误导性结果与可迁移性问题，现有的研究仅考虑周围车辆产生危险行为会限制整体风险评估，因为行人和环境因素可能引入新风险与挑战，需在危险场景生成中予以考虑，忽略这些因素可能导致对风险低估，无法全面评估自动驾驶系统在复杂多变环境中行为和决策能力，当前研究仅利用背景车辆初始运行条件如位置、速度、航向角等构造驾驶场景参数空间，所以应定义更高维参数空间以精细化和全面表征自动驾驶性能边界，当处理高维参数空间和昂贵自动驾驶仿真评价时，通用启发式智能优化算法往往不再适用，能有效求解的优化算法非常有限，在这种情况下，很有必要借助代理建模、最优计算资源分配、样本填充策略等技术设计相应随机或鲁棒仿真优化算法，这也是本项目研究的关键点。

当前世界最先进的自动驾驶方案里端到端自动驾驶有较强感知性能和泛化能力构建的系统更简单智能，然而现有的端到端自动驾驶决策方法存在如下问题，一是端到端自动驾驶模型依赖训练数据面对复杂和危险场景可能做出不合理决策，二是端到端自动驾驶依赖深度神经网络其黑盒特性让决策过程难以解释限制系统行为理解和调试，三是端到端自动驾驶模型从图像或点云直接输出控制信号训练中难全面理解复杂交通环境无法考虑多重因素导致决策缺乏适应性和灵活性，本研究的终极目标是为端到端自动驾驶设计富含驾驶语义信息的输入并利用先进神经网络架构突破以往自动驾驶性能边界 。

本研究紧紧围绕自动驾驶场景生成和安全评估核心问题展开，深入探索并提出ChatScene与ASIL - Gen协同解决方案，成功构建起从场景高效生成到精准风险评估完整技术体系，为自动驾驶测试领域带来创新性突破，在场景生成层面，ChatScene框架展现出独特的技术优势。
其创新性地融合 Scenic 语言、深度强化学习与 GPT-4o 模型，场景生成模式实现了多元化与智能化发展。在固定场景模式里，基于Scenic语言预定义的8类基准场景，这些场景涵盖城市主干道、高速公路以及乡村道路等多种典型交通环境，利用深度强化学习中的SAC算法，以碰撞避免、车道保持和速度优化等作为核心奖励函数，对场景里对抗行为参数展开精细化调整与优化，以此模拟出高度真实且复杂多变的交通参与者交互行为，为自动驾驶系统提供标准化与规范化的测试场景模板。在动态模式方面，借助GPT - 4强大的自然语言理解与代码生成能力，用户只要输入自然语言描述，像“暴雨天气下，自我车辆在无信号灯十字路口左转，对向车辆突然加速直行”这样的内容，系统就能快速解析语义信息并将其转化为符合CARLA 0.9.13规范的场景代码。通过设定详细的约束条件，包含道路类型、车辆动力学参数以及交通规则等内容，生成多样化且贴近真实驾驶场景的测试用例，相比传统基于LiDARGen的场景生成方法，，动态模式的生成效率提升了 107 倍，极大地丰富了自动驾驶测试场景的多样性与灵活性，显著提高了测试效率\cite{焦准2006基于证据理论的多传感器信息融合目标识别方法}。​

在安全评估领域当中ASIL - Gen起到了关键作用，该模块借助NSGA - II多目标优化算法以及基于ISO 26262标准的量化评估模型，达成了场景的优化筛选与科学分类工作。在场景生成这个阶段，基于基础场景模板依靠脚本自动化生成13类场景变体，其中涵盖动态障碍物交叉、无信号路口冲突、恶劣天气下跟车等复杂情况，并且通过调整障碍物位置、速度、交通流量等参数，形成海量多样化的测试场景。在此基础之上，利用NSGA - II算法把碰撞概率与场景复杂度当作双目标函数来进行优化。碰撞概率通过精确预测车辆、行人等交通参与者的运动轨迹来计算，场景复杂度则综合考虑交通参与者数量、道路拓扑结构、环境干扰因素等多个指标，进而搜索出帕累托前沿筛选出既具高风险价值又有代表性的场景。实验数据表明，通过ASIL - Gen优化之后，高风险ASIL - D等级场景占比从随机搜索的5\%提升到12\%，经过进一步优化后更是提升至15\%，显著增强了场景，显著增强了场景筛选的精准性与安全评估的科学性。​

在实验验证这个重要环节当中本研究取得一系列有说服力成果，基于ChatScene训练的RL模型在行人横穿场景测试里和基线模型开展多次重复对比实验，通过精确统计碰撞次数得出结果表明其碰撞率降低了32\%，这充分验证了ChatScene与ASIL - Gen协同方案对提升自动驾驶系统鲁棒性有效，同时场景生成效率以及安全评估准确性等方面实验数据有力证明该方案在自动驾驶技术安全测试中具巨大应用价值，为自动驾驶技术的安全测试开辟新的技术路径与研究方向。

安全模型，英伟达的安全力场（SFF）和Mobileye的责任敏感安全（RSS）等对决策来说是有可解释性的数学模型。这项工作从头开始实现SFF，替代未公开的英伟达源代码，并将其与CARLA开源模拟器集成。使用SFF和CARLA，提出了一个车辆声明集合的预测器，并以此提出一种综合驾驶策略，无论在通过动态交通时遇到什么安全条件，其都能持续运行。该策略没有针对每种情况制定单独的规划，但利用安全潜能，目的是将类人的驾驶融入交通流中。



责任敏感安全（RSS）将自车的危险时间t与纵向/横向的危险阈值时间tlong/tlat进行比较。如果达到阈值，RSS判断为危险情况，并根据纵向或横向加速度对速度的限制做出适当的响应。换句话说，阈值可以用轨迹集的多边形表示。如果自车和其他道路使用者之间的轨迹集相交，RSS会选择以下三个决策中的一个来恢复安全状态：刹车，继续前进或开车离开。

安全力场（SFF）表示，如果参与者遵循安全程序（这是一系列控制策略），量化风险的安全潜能ρAB不会再增加，因此可以保证参与者最终不会造成不安全的情况。这可以通过安全潜能的链式法则从数学上证明。简而言之，RSS的方法是最小化参与者声称集合之间的交集，这是每个参与者安全程序产生轨迹的联合。

英特尔发布了一个名为ad-rss-lib的开源库，该库部分实现了RSS。此外，NVIDIA还提供了一个名为DriveWorks SDK的软件开发工具包，其中包括针对经批准用户的SFF实现。Intel ad-rss-lib没有涵盖其论文的全部范围，但它提供了Python绑定和CARLA集成。然而，NVIDIA DriveWorks SDK是一个非公开IP，它的实现是为了与配备NVIDIA DRIVE OS的NVIDIA DRIVE平台集成，因此研究人员很少使用它。在Intel和NVIDIA建议的将RSS和SFF与现有自动驾驶系统集成的基本示例架构中，RSS和SFF扮演着最后的角色，通过重写规划子系统的决策来防止自动驾驶车辆发生碰撞。

在SFF实施中使用声明集合和安全潜能的概念，声明集合就是安全程序（驾驶策略）获取的轨迹之联合，安全潜能是两个参与者的声明集合之间相交测度及其负梯度。该文提出了一种将SFF集成到规划子系统中的方法，制定一种类似人类的驾驶策略，无论在安全或不安全的条件下都能始终如一地运行，最终尽量不阻碍顺畅的交通流。

Intel RSS或NVIDIA SFF作为与现有子系统协调的附加模块。它接收来自感知子系统的世界环境数据和来自规划子系统的机动决策。为了自车的安全，作为上层限制器，它可以推翻接收的决策，并将限制的决策传递给驾驶子系统。如图是具有RSS或SFF安全模型的基本示例架构：灰色是现有子系统部分，蓝色/绿色是附加模块的RSS/SFF实现部分\cite{陈华0面向智能辅助驾驶系统的驾驶员行为分析与建模}。

\subsection{展望}


虽然本研究在自动驾驶场景生成和安全评估领域有了一定成果，但面对自动驾驶技术快速发展带来的需求和挑战，该领域还有很多需要深入探索的方向，未来研究可以从以下多个维度来开展，深化多模态数据融合方面，目前自动驾驶场景生成主要依靠有限的数据源，未来研究要进一步深化多模态数据融合，除了持续探索激光雷达和摄像头数据的深度融合，还会引入毫米波雷达数据，借助其在恶劣天气下稳定的探测性能，提高场景中目标检测与跟踪的准确性，同时融合高精地图数据，把地图里的道路属性、交通标志、车道线等信息和传感器数据相结合，构建更贴近真实驾驶环境的场景生成模型，通过多模态数据的协同处理与特征融合，不但能提升场景的物理真实性，还能增强场景的语义准确性，让生成的场景更符合实际驾驶过程中的复杂状况，为自动驾驶系统提供更具挑战性与真实性的测试环境。​

拓展 ASIL 分类标准：现有的 ASIL 分类标准主要基于静态的交通场景因素，未来将结合车路协同、交通流理论等前沿技术，对其进行拓展与完善。将 V2X 通信状态纳入评估体系，考虑车辆与车辆、车辆与基础设施之间的信息交互对驾驶安全的影响；同时引入交通拥堵态势分析，结合交通流模型，评估不同拥堵程度下自动驾驶系统面临的风险。此外，还将探索驾驶员行为模型与 ASIL 分类的结合，分析人类驾驶行为的不确定性对自动驾驶系统安全的潜在影响，从而完善高风险场景的识别维度，使 ASIL 分类标准更全面、准确地反映自动驾驶系统在复杂交通环境下的安全风险状况。​

探索模型轻量化与实时化：随着自动驾驶技术向边缘设备的不断渗透，算力受限成为制约实时在线评估的关键因素。未来研究将致力于探索 ChatScene 与 ASIL-Gen 算法架构的轻量化与实时化优化。一方面，通过模型压缩技术，如剪枝、量化等方法，减少模型参数与计算量；另一方面，采用高效的算法优化策略，如改进的神经网络结构、并行计算技术等，提高算法执行效率。针对边缘设备的硬件特性，开发专用的轻量化模型，使其能够在资源有限的条件下快速生成场景并进行安全评估，推动自动驾驶仿真测试从离线分析向实时在线评估方向发展，为自动驾驶车辆的实时决策与安全监控提供有力支持，加速自动驾驶技术的落地应用进程。​

强化人机协同测试模式：考虑到自动驾驶系统最终服务于人类出行，未来可探索将人类驾驶员的行为与决策纳入测试体系，构建人机协同的测试模式。通过收集和分析人类驾驶数据，模拟不同驾驶风格、驾驶习惯的人类驾驶员与自动驾驶系统的交互场景，评估自动驾驶系统在人机共驾环境下的安全性与适应性。同时，研究如何利用人类驾驶员的经验与直觉，辅助自动驾驶系统进行决策，实现人机优势互补，进一步提升自动驾驶系统的可靠性与用户接受度。​

开展跨地域与跨文化场景研究：目前的研究主要基于特定地域的交通规则与驾驶习惯，未来将开展跨地域与跨文化场景研究。收集不同国家、不同地区的交通数据，分析其交通规则、驾驶文化的差异，构建多样化的跨地域场景库。通过在这些场景下对自动驾驶系统进行测试与评估，确保自动驾驶技术在全球范围内的适用性与安全性，推动自动驾驶技术的全球化发展。







\newpage



