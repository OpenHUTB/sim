\section*{附录：系统模块源代码}

\subsection*{自然语言理解与场景生成模块}
\begin{enumerate}
	\item \texttt{retrieve.py}
	\begin{itemize}
		\item 该文件是系统的主文件，负责从自然语言描述中生成场景代码。它集成了自然语言处理和检索增强模块，通过调用大语言模型生成符合输入语义的Scenic场景脚本。
	\end{itemize}
	\begin{verbatim}
import os
import setGPU
import csv
import pickle
import re
from sentence_transformers import SentenceTransformer, models
from os import path as osp
from tqdm import tqdm
import argparse
from architecture import LLMChat
from utils import load_file, retrieve_topk, generate_code_snippet, save_scenic_code


# no need for faiss currently
# import faiss

# Argument parsing
parser = argparse.ArgumentParser(description="Set up configurations for your script.")
parser.add_argument('--port_ip', type=int, default=2000, help='Port IP address (default: 2000)')
parser.add_argument('--topk', type=int, default=3, help='Top K value (default: 3) for retrieval')
parser.add_argument('--model', type=str, default='gpt-4o', help="Model name (default: 'gpt-4o'), also support transformers model")
parser.add_argument('--use_llm', action='store_true', help='if use llm for generating new snippets')
args = parser.parse_args()

# Configuration
port_ip = args.port_ip
topk = args.topk
use_llm = args.use_llm

# LLM model initialization
llm_model = LLMChat(args.model)
local_path = osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__))))
extraction_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'extraction.txt'))
behavior_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'behavior.txt'))
geometry_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'geometry.txt'))
spawn_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'spawn.txt'))
scenario_descriptions = load_file(osp.join(local_path, 'retrieve', 'scenario_descriptions.txt')).split('\n')

# 🔥 修改开始：本地加载 sentence-t5-large 模型
model_dir = r"D:\sceneMain\chatScene\models\sentence-t5-large"
if not os.path.exists(model_dir):
raise FileNotFoundError(f"本地模型路径不存在：{model_dir}")

required_files = ["config.json", "pytorch_model.bin"]
for filename in required_files:
if not os.path.exists(os.path.join(model_dir, filename)):
raise FileNotFoundError(f"缺少必要的文件: {filename} 在 {model_dir} 中")

word_embedding_model = models.Transformer(model_dir, max_seq_length=512)
pooling_model = models.Pooling(
word_embedding_model.get_word_embedding_dimension(),
pooling_mode='mean'
)
encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda')
print("✅ 成功加载本地 sentence-t5-large 模型！")
# 🔥 修改结束

# Load the database
with open(osp.join(local_path, 'retrieve/database_v1.pkl'), 'rb') as file:
database = pickle.load(file)

behavior_descriptions = database['behavior']['description']
geometry_descriptions = database['geometry']['description']
spawn_descriptions = database['spawn']['description']
behavior_snippets = database['behavior']['snippet']
geometry_snippets = database['geometry']['snippet']
spawn_snippets = database['spawn']['snippet']

behavior_embeddings = encoder.encode(behavior_descriptions, device='cuda', convert_to_tensor=True)
geometry_embeddings = encoder.encode(geometry_descriptions, device='cuda', convert_to_tensor=True)
spawn_embeddings = encoder.encode(spawn_descriptions, device='cuda', convert_to_tensor=True)

# This is the head for scenic file, you can modify the carla map or ego model here
head = '''param map = localPath(f'../maps/{Town}.xodr') 
param carla_map = Town
model scenic.simulators.carla.model
EGO_MODEL = "vehicle.lincoln.mkz_2017"
'''

log_file_path = osp.join(local_path, 'safebench', 'scenario', 'scenario_data', 'scenic_data', 'dynamic_scenario', 'dynamic_log.csv')

# Write log results
with open(log_file_path, mode='w', newline='') as file:
log_writer = csv.writer(file)
log_writer.writerow(['Scenario', 'AdvObject', 'Behavior Description', 'Behavior Snippet', 'Geometry Description', 'Geometry Snippet', 'Spawn Description', 'Spawn Snippet', 'Success'])

# Process each scenario description
for q, current_scenario in tqdm(enumerate(scenario_descriptions)):
messages = [
{"role": "system", "content": "You are a helpful assistant."},
{"role": "user", "content": extraction_prompt.format(scenario=current_scenario)},
]

response = llm_model.generate(messages)

try:
match = re.search(r"Adversarial Object:(.*?)Behavior:(.*?)Geometry:(.*?)Spawn Position:(.*)", response, re.DOTALL)
if not match:
raise ValueError("Failed to extract components from the response")

current_adv_object, current_behavior, current_geometry, current_spawn = [s.strip() for s in match.groups()]

# Retrieve the top K relevant snippets
top_behavior_descriptions, top_behavior_snippets = retrieve_topk(encoder, topk, behavior_descriptions, behavior_snippets, behavior_embeddings, current_behavior)
top_geometry_descriptions, top_geometry_snippets = retrieve_topk(encoder, topk, geometry_descriptions, geometry_snippets, geometry_embeddings, current_geometry)
top_spawn_descriptions, top_spawn_snippets = retrieve_topk(encoder, topk, spawn_descriptions, spawn_snippets, spawn_embeddings, current_spawn)

# Generate code snippets using the LLM
generated_behavior_code = generate_code_snippet(
llm_model, behavior_prompt, top_behavior_descriptions, top_behavior_snippets, current_behavior, topk, use_llm
)

generated_geometry_code = generate_code_snippet(
llm_model, geometry_prompt, top_geometry_descriptions, top_geometry_snippets, current_geometry, topk, use_llm
)

generated_spawn_code = generate_code_snippet(
llm_model, spawn_prompt, top_spawn_descriptions, top_spawn_snippets, current_spawn, topk, use_llm
)

# Log the results
log_writer.writerow([current_scenario, current_adv_object, current_behavior, generated_behavior_code, current_geometry, generated_geometry_code, current_spawn, generated_spawn_code, 1])

Town, generated_geometry_code = generated_geometry_code.split('\n', 1)
scenic_code = '\n'.join([f"'''{current_scenario}'''", Town, head, generated_behavior_code, generated_geometry_code, generated_spawn_code.format(AdvObject=current_adv_object)])
save_scenic_code(local_path, port_ip, scenic_code, q)

except Exception as e:
log_writer.writerow([current_scenario, '', '', '', '', '', '', '', 0])
print(f"Failure for scenario: {current_scenario} - Error: {e}")

	\end{verbatim}
	
	\item \texttt{scenario\_descriptions.txt}
	\begin{itemize}
		\item 该文本文件包含预定义的自然语言描述数据集，用于场景生成的检索增强。系统通过读取该文件中的场景描述来进行相似描述的检索与匹配。
	\end{itemize}
	\begin{verbatim}

	\end{verbatim}
	
	\item \texttt{architecture.py}
	\begin{itemize}
		\item 配置文件，定义了系统架构相关的参数，包括模型加载路径、仿真平台设置、输出目录等。该文件在系统初始化时提供必要的配置支持，确保模块之间的协调工作。
	\end{itemize}
	\begin{verbatim}
import openai
import torch
import transformers

# 设置 OpenAI API 密钥和 API 基础地址
openai.api_key = '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'

class LLMChat:
def __init__(self, model_name='gpt-4', use_gpu=True):
"""
初始化聊天模型。
- model_name: 使用的模型名称（例如 'gpt-4' 或 HuggingFace 模型名称）。
- use_gpu: 是否使用 GPU（默认是 True）。
"""
super(LLMChat, self).__init__()
self.model_name = model_name
self.use_gpu = use_gpu

if model_name.startswith('gpt'):
self.client = openai  # 直接用 openai，不需要 openai.OpenAI()
else:
self.device = "cuda" if torch.cuda.is_available() and use_gpu else "cpu"
self.pipeline = transformers.pipeline(
"text-generation",
model=model_name,
model_kwargs={"torch_dtype": torch.float32},
device=0 if self.device == "cuda" else -1,
)

def generate(self, messages, max_new_tokens=500):
"""
生成文本。
- messages: 输入消息（适用于 GPT 模型和 HuggingFace 模型）。
- max_new_tokens: 最大生成的 tokens 数量。
"""
if self.model_name.startswith('gpt'):
response = self.client.chat.completions.create(
model=self.model_name,
messages=messages,
temperature=0.7,
max_tokens=max_new_tokens,
)
return response.choices[0].message.content.strip()
else:
if isinstance(messages, str):
messages = [{"role": "user", "content": messages}]
outputs = self.pipeline(
messages[0]['content'],
max_new_tokens=max_new_tokens,
do_sample=True,
)
return outputs[0]["generated_text"].strip()

	\end{verbatim}
\end{enumerate}

\subsection*{场景合成与仿真模块}
\begin{enumerate}
	\item \texttt{run\_train\_dynamic.py}
	\begin{itemize}
		\item 作用：用于在动态生成的场景上训练代理。该文件使用 \texttt{dynamic\_scenic.yaml} 进行配置，并运行训练过程，优化代理的行为。
	\end{itemize}
	\begin{verbatim}
	import setGPU
	import traceback
	import os
	import os.path as osp
	
	import torch 
	from safebench.util.run_util import load_config
	from safebench.util.torch_util import set_seed, set_torch_variable
	from safebench.carla_runner import CarlaRunner
	from safebench.scenic_runner_dynamic import ScenicRunner
	
	if __name__ == '__main__':
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--exp_name', type=str, default='exp')
	parser.add_argument('--output_dir', type=str, default='log')
	parser.add_argument('--ROOT_DIR', type=str, default=osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__)))))
	
	parser.add_argument('--max_episode_step', type=int, default=300)
	parser.add_argument('--auto_ego', action='store_true')
	parser.add_argument('--mode', '-m', type=str, default='eval', choices=['train_scenario', 'train_agent', 'eval'])
	parser.add_argument('--agent_cfg', nargs='*', type=str, default=['adv_scenic.yaml'])
	parser.add_argument('--scenario_cfg', nargs='*', type=str, default=['dynamic_scenic.yaml'])
	parser.add_argument('--continue_agent_training', '-cat', type=bool, default=False)
	parser.add_argument('--continue_scenario_training', '-cst', type=bool, default=False)
	
	parser.add_argument('--seed', '-s', type=int, default=0)
	parser.add_argument('--threads', type=int, default=4)
	parser.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')   
	
	parser.add_argument('--num_scenario', '-ns', type=int, default=1, help='num of scenarios we run in one episode')
	parser.add_argument('--save_video', action='store_true')
	parser.add_argument('--render', type=bool, default=True)
	parser.add_argument('--frame_skip', '-fs', type=int, default=1, help='skip of frame in each step')
	parser.add_argument('--port', type=int, default=2002, help='port to communicate with carla')
	parser.add_argument('--tm_port', type=int, default=8002, help='traffic manager port')
	parser.add_argument('--fixed_delta_seconds', type=float, default=0.1)
	args = parser.parse_args()
	args_dict = vars(args)
	
	err_list = []
	for agent_cfg in args.agent_cfg:
	for scenario_cfg in args.scenario_cfg:
	# set global parameters
	set_torch_variable(args.device)
	torch.set_num_threads(args.threads)
	set_seed(args.seed)
	
	# load agent config
	agent_config_path = osp.join(args.ROOT_DIR, 'safebench/agent/config', agent_cfg)
	agent_config = load_config(agent_config_path)
	
	# load scenario config
	scenario_config_path = osp.join(args.ROOT_DIR, 'safebench/scenario/config', scenario_cfg)
	scenario_config = load_config(scenario_config_path)
	
	agent_config['load_dir'] = osp.join(agent_config['load_dir'], 'dynamic_scenario')
	# Check if the directory exists; if not, create it
	if not osp.exists(agent_config['load_dir']):
	os.makedirs(agent_config['load_dir'])        
	
	# main entry with a selected mode
	agent_config.update(args_dict)
	args_dict['output_dir'] = osp.join('log', 'adv_train', args.mode, agent_config['policy_name'], f"{agent_cfg.split('.')[0]}", "dynamic_scenario")
	scenario_config.update(args_dict)
	scenario_config['num_scenario'] = 1 ### 'the num_scenario can only be one for scenic'
	runner = ScenicRunner(agent_config, scenario_config)
	
	
	# start running
	runner.run()
	
	for err in err_list:
	print(err[0], err[1], 'failed!')
	print(err[2])
	

	\end{verbatim}
	
	\item \texttt{dynamic\_scenic.yaml}
	\begin{itemize}
		\item 作用：该文件是代理的配置文件，包含了代理的训练设置，包括其行为模型、对抗性行为、场景属性等。它与其他 YAML 文件结合使用来指定代理在不同场景中的行为。
	\end{itemize}
	\begin{verbatim}
	policy_type: 'scenic'
	scenario_category: 'scenic'
	
	route_dir: 'safebench/scenario/scenario_data/route'
	scenic_dir: 'safebench/scenario/scenario_data/scenic_data/'
	sample_num: 50
	opt_step: 10
	select_num: 2
	
	method: 'scenic'
	scenario_id: null
	route_id: [0,1,2,3,4,5,6,7]
	
	ego_action_dim: 2
	ego_state_dim: 4
	ego_action_limit: 1.0
	
	\end{verbatim}
\end{enumerate}

\subsection*{评估与展示模块}
\begin{enumerate}
	\item \texttt{evaluate\_scene\_quality.py}
	\begin{itemize}
		\item 该文件负责对生成的场景进行量化评估，输出语义保真度、多样性与驾驶性能相关指标。
	\end{itemize}
	\begin{verbatim}
import os
import json
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import pairwise_distances_argmin_min
import cv2

# 文件路径
DESCRIPTION_FILE = 'D:/sceneMain/chatScene/retrieve/scenario_descriptions.txt'
HISTORY_FILE = 'D:/sceneMain/chatScene/retrieve/scenario_history.txt'
SCENE_IMAGE_DIR = 'D:/sceneMain/chatScene/outputs/'

# 加载最新的场景描述（只读取文件的第一行）
def load_latest_description(path):
"""只读取描述文件中的第一行"""
with open(path, 'r', encoding='utf-8') as f:
first_line = f.readline().strip()  # 读取第一行
return first_line

# 将新的场景描述追加到历史记录文件
def append_to_history(new_description, history_path):
"""将新的场景描述追加到历史文件"""
with open(history_path, 'a', encoding='utf-8') as f:
f.write(new_description + '\n')

# 计算图像相似度（使用结构相似度）
def calculate_image_similarity(image1, image2):
"""计算两张图像之间的相似度"""
gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
score, _ = cv2.quality.QualitySSIM_compute(gray1, gray2)
return score

# 计算场景的多样性（使用生成图像之间的距离）
def calculate_scene_diversity(image_dir):
"""计算所有图像之间的多样性"""
images = []
for filename in os.listdir(image_dir):
if filename.endswith('.png'):
img = cv2.imread(os.path.join(image_dir, filename))
images.append(img)

# 转换为数组（每个图像的特征）
image_features = [np.reshape(img, (-1, 3)) for img in images]
image_features = np.concatenate(image_features, axis=0)

# 计算每对图像的最小距离
distances = pairwise_distances_argmin_min(image_features, image_features)
avg_distance = np.mean(distances[1])  # 平均最小距离
return avg_distance

# 评估场景质量：语义一致性，图像质量，多样性
def evaluate_scene_quality(image_dir):
"""评估场景的质量"""

# 语义一致性（假设为手动指定或从其他方法中获得）
semantic_consistency = 0.9  # 假设的值，通常需要根据具体情况进行计算

# 图像质量：假设使用已有的参考图像进行评估（此处为一个示例）
reference_image = cv2.imread('D:/sceneMain/chatScene/reference_image.png')  # 参考图像
image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]
avg_image_quality = 0
for image_file in image_files:
img = cv2.imread(os.path.join(image_dir, image_file))
similarity = calculate_image_similarity(reference_image, img)
avg_image_quality += similarity
avg_image_quality /= len(image_files)

# 多样性
diversity = calculate_scene_diversity(image_dir)

# 打印评估结果
print(f"语义一致性: {semantic_consistency}")
print(f"平均图像质量: {avg_image_quality}")
print(f"场景多样性: {diversity}")

return semantic_consistency, avg_image_quality, diversity

# 主函数
def main():
# 读取最新的场景描述
latest_description = load_latest_description(DESCRIPTION_FILE)

# 将描述追加到历史记录
append_to_history(latest_description, HISTORY_FILE)

# 打印最新描述
print(f"最新的场景描述: {latest_description}")

# 评估生成的场景质量
semantic_consistency, avg_image_quality, diversity = evaluate_scene_quality(SCENE_IMAGE_DIR)

# 可以根据需要将评估结果保存为JSON或其他格式
evaluation_results = {
	"semantic_consistency": semantic_consistency,
	"avg_image_quality": avg_image_quality,
	"diversity": diversity
}

# 保存评估结果到文件
with open('D:/sceneMain/chatScene/outputs/evaluation_results.json', 'w') as f:
json.dump(evaluation_results, f, indent=4)

if __name__ == "__main__":
main()

	\end{verbatim}
	
	\item \texttt{run\_eval\_dynamic.py}
	\begin{itemize}
		\item 该文件用于运行评估流程，调用 \texttt{evaluate\_scene\_quality.py} 对生成的场景进行评估。
	\end{itemize}
	\begin{verbatim}
	import setGPU
	import traceback
	import os.path as osp
	
	import torch 
	
	from safebench.util.run_util import load_config
	from safebench.util.torch_util import set_seed, set_torch_variable
	from safebench.carla_runner import CarlaRunner
	from safebench.scenic_runner_dynamic import ScenicRunner
	
	if __name__ == '__main__':
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--exp_name', type=str, default='exp')
	parser.add_argument('--output_dir', type=str, default='log')
	parser.add_argument('--ROOT_DIR', type=str, default=osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__)))))
	
	parser.add_argument('--max_episode_step', type=int, default=300)
	parser.add_argument('--auto_ego', action='store_true')
	parser.add_argument('--mode', '-m', type=str, default='eval', choices=['train_agent', 'train_scenario', 'eval'])
	parser.add_argument('--agent_cfg', nargs='*', type=str, default=['adv_scenic.yaml'])
	parser.add_argument('--scenario_cfg', nargs='*', type=str, default=['dynamic_scenic.yaml'])
	parser.add_argument('--continue_agent_training', '-cat', type=bool, default=False)
	parser.add_argument('--continue_scenario_training', '-cst', type=bool, default=False)
	
	parser.add_argument('--seed', '-s', type=int, default=0)
	parser.add_argument('--threads', type=int, default=4)
	parser.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')   
	
	parser.add_argument('--num_scenario', '-ns', type=int, default=2, help='num of scenarios we run in one episode')
	parser.add_argument('--save_video', action='store_true')
	parser.add_argument('--render', type=bool, default=True)
	parser.add_argument('--frame_skip', '-fs', type=int, default=1, help='skip of frame in each step')
	parser.add_argument('--port', type=int, default=2002, help='port to communicate with carla')
	parser.add_argument('--tm_port', type=int, default=8002, help='traffic manager port')
	parser.add_argument('--fixed_delta_seconds', type=float, default=0.1)
	parser.add_argument('--test_policy', type=str, default='sac')
	parser.add_argument('--test_epoch', type=int, default=None)
	args = parser.parse_args()
	
	err_list = []
	for agent_cfg in args.agent_cfg:
	for scenario_cfg in args.scenario_cfg:
	# set global parameters
	set_torch_variable(args.device)
	torch.set_num_threads(args.threads)
	set_seed(args.seed)
	
	# load agent config
	agent_config_path = osp.join(args.ROOT_DIR, 'safebench/agent/config', agent_cfg)
	agent_config = load_config(agent_config_path)
	agent_config['policy_name'] = args.test_policy
	
	## load the corresponding model ##
	agent_config['load_dir'] = osp.join(agent_config['load_dir'], "dynamic_scenario")
	
	# load scenario config
	scenario_config_path = osp.join(args.ROOT_DIR, 'safebench/scenario/config', scenario_cfg)
	scenario_config = load_config(scenario_config_path)
	
	args.output_dir = osp.join('log', 'adv_train', args.mode, agent_config['policy_name'], f"{agent_cfg.split('.')[0]}_epoch{args.test_epoch}")
	args.exp_name =  "dynamic_scenario"
	args_dict = vars(args)
	# main entry with a selected mode
	agent_config.update(args_dict)
	print(agent_config['load_dir'])
	scenario_config.update(args_dict)
	
	scenario_config['num_scenario'] = 1 # 'the num_scenario can only be one for scenic'
	runner = ScenicRunner(agent_config, scenario_config)
	
	# start running
	try:
	runner.run(args.test_epoch)
	except:
	runner.close()
	traceback.print_exc()
	err_list.append([agent_cfg, scenario_cfg, traceback.format_exc()])
	
	for err in err_list:
	print(err[0], err[1], 'failed!')
	print(err[2])
	
	\end{verbatim}
\end{enumerate}